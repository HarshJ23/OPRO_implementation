{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPRO Implementation for MMLU Computer Science Questions\n",
    "### Modified version of Google DeepMind's OPRO framework optimizing for both accuracy and token count efficiency\n",
    "#### paper link : https://arxiv.org/abs/2309.03409\n",
    "\n",
    "\n",
    "#### to understand the underlying concept in layman terms check this simple presentation prepared by me : [Presentation](https://docs.google.com/presentation/d/1aTT6bXf9I1mFAhU5kmMMWRcUwsygnGRaXZ65U29SpWM/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (1.26.4)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: pandas in c:\\python311\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: openai in c:\\python311\\lib\\site-packages (1.35.2)\n",
      "Requirement already satisfied: tqdm in c:\\python311\\lib\\site-packages (4.66.4)\n",
      "Requirement already satisfied: tiktoken in c:\\python311\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python311\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\python311\\lib\\site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\python311\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\python311\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\python311\\lib\\site-packages (from openai) (2.7.2)\n",
      "Requirement already satisfied: sniffio in c:\\python311\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\python311\\lib\\site-packages (from openai) (4.12.0)\n",
      "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\python311\\lib\\site-packages (from tiktoken) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\python311\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\python311\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in c:\\python311\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas openai tqdm tiktoken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class OptimizationConfig:\n",
    "    \"\"\"Configuration parameters for optimization process\"\"\"\n",
    "    max_steps: int = 150  # max optimization steps\n",
    "    solutions_per_step: int = 8  # sol. generated per step\n",
    "    max_history: int = 20  # max no. of previous solutions to keep\n",
    "    temperature: float = 1.0  \n",
    "    token_weight: float = 0.3  # weightage of token length for scoring\n",
    "    max_tokens: int = 150  # token limit\n",
    "\n",
    "@dataclass\n",
    "class Solution:\n",
    "    \"\"\"Structure to hold solution data\"\"\"\n",
    "    instruction: str\n",
    "    accuracy: float\n",
    "    token_count: int\n",
    "    combined_score: float = 0.0\n",
    "    \n",
    "    def calculate_score(self, token_weight: float, max_tokens: int):\n",
    "        \"\"\"Calculate combined score considering both accuracy and token efficiency\"\"\"\n",
    "        token_score = 1 - (self.token_count / max_tokens)\n",
    "        self.combined_score = (1 - token_weight) * self.accuracy + token_weight * token_score\n",
    "        return self.combined_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Section : Token Management\n",
    "##### Implement functions for token counting and management\n",
    "\n",
    "\n",
    "class TokenManager:\n",
    "    def __init__(self):\n",
    "        self.encoder = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "        \n",
    "    def count_tokens(self, text: str) -> int:\n",
    "        \"\"\"Count tokens in given text\"\"\"\n",
    "        return len(self.encoder.encode(text))\n",
    "    \n",
    "    def is_within_limit(self, text: str, max_tokens: int) -> bool:\n",
    "        \"\"\"Check if text is within token limit\"\"\"\n",
    "        return self.count_tokens(text) <= max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MMLU dataset handler\n",
    "\n",
    "class MMluDataHandler:\n",
    "    def __init__(self, data_path: str):\n",
    "        \"\"\"Initialize with path to MMLU CS data\"\"\"\n",
    "        self.data = pd.read_csv(data_path)\n",
    "        self.train_data = None\n",
    "        self.test_data = None\n",
    "        \n",
    "    def prepare_data(self, train_ratio: float = 0.2):\n",
    "        \"\"\"split data into train and test sets\"\"\"\n",
    "        mask = np.random.rand(len(self.data)) < train_ratio\n",
    "        self.train_data = self.data[mask]\n",
    "        self.test_data = self.data[~mask]\n",
    "        \n",
    "    def get_sample_questions(self, n: int, from_train: bool = True) -> pd.DataFrame:\n",
    "        \"\"\"Get n random questions from dataset\"\"\"\n",
    "        source = self.train_data if from_train else self.test_data\n",
    "        return source.sample(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scorer component\n",
    "\n",
    "class Scorer:\n",
    "    def __init__(self, model: str = \"gpt-3.5-turbo\"):\n",
    "        self.model = model\n",
    "        self.token_manager = TokenManager()\n",
    "        \n",
    "    def evaluate_solution(self, instruction: str, questions: pd.DataFrame) -> Tuple[float, int]:\n",
    "        \"\"\"Evaluate solution's accuracy and token count\"\"\"\n",
    "        correct = 0\n",
    "        token_count = self.token_manager.count_tokens(instruction)\n",
    "        \n",
    "        for _, row in questions.iterrows():\n",
    "            prompt = self._create_evaluation_prompt(instruction, row)\n",
    "            response = self._get_model_response(prompt)\n",
    "            if self._is_correct_answer(response, row['answer']):\n",
    "                correct += 1\n",
    "                \n",
    "        accuracy = correct / len(questions)\n",
    "        return accuracy, token_count\n",
    "    \n",
    "    def _create_evaluation_prompt(self, instruction: str, question_data: pd.Series) -> str:\n",
    "        \"\"\"Create prompt for evaluation\"\"\"\n",
    "        return f\"{instruction}\\n\\nQuestion: {question_data['question']}\\nA) {question_data['A']}\\nB) {question_data['B']}\\nC) {question_data['C']}\\nD) {question_data['D']}\"\n",
    "    \n",
    "    def _get_model_response(self, prompt: str) -> str:\n",
    "        \"\"\"Get response from OpenAI API\"\"\"\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=self.model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"API Error: {e}\")\n",
    "            return \"\"\n",
    "    \n",
    "    def _is_correct_answer(self, response: str, correct_answer: str) -> bool:\n",
    "        \"\"\"Check if response matches correct answer\"\"\"\n",
    "        return correct_answer.upper() in response.upper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## optimization component - core logic behind optimization\n",
    "class OptimizerEngine:\n",
    "    def __init__(self, config: OptimizationConfig):\n",
    "        self.config = config\n",
    "        self.scorer = Scorer()\n",
    "        self.token_manager = TokenManager()\n",
    "        self.solutions_history: List[Solution] = []\n",
    "        \n",
    "    def create_meta_prompt(self, exemplars: pd.DataFrame) -> str:\n",
    "        \"\"\"Create meta-prompt for optimization\"\"\"\n",
    "        # Sort solutions by combined score\n",
    "        sorted_solutions = sorted(\n",
    "            self.solutions_history[-self.config.max_history:],\n",
    "            key=lambda x: x.combined_score,\n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        # Create prompt with previous solutions\n",
    "        solutions_text = \"\\n\".join([\n",
    "            f\"instruction: {sol.instruction}\\naccuracy: {sol.accuracy:.2f}\\ntokens: {sol.token_count}\\nscore: {sol.combined_score:.2f}\"\n",
    "            for sol in sorted_solutions\n",
    "        ])\n",
    "        \n",
    "        # Add exemplars\n",
    "        exemplars_text = \"\\n\\n\".join([\n",
    "            f\"Example {i+1}:\\n{row['question']}\\nA) {row['A']}\\nB) {row['B']}\\nC) {row['C']}\\nD) {row['D']}\\nCorrect: {row['answer']}\"\n",
    "            for i, (_, row) in enumerate(exemplars.iterrows())\n",
    "        ])\n",
    "        \n",
    "        return f\"\"\"You are an AI instruction optimizer. Create a new instruction for answering computer science questions that:\n",
    "1. Maximizes accuracy in answering questions\n",
    "2. Uses minimal number of tokens (be concise but effective)\n",
    "3. Is different from previous instructions\n",
    "\n",
    "Previous solutions (sorted by combined score):\n",
    "{solutions_text}\n",
    "\n",
    "Example questions:\n",
    "{exemplars_text}\n",
    "\n",
    "Generate a new instruction that should perform better than previous ones while being concise.\n",
    "Instruction should be specific to computer science domain and help in answering multiple-choice questions.\n",
    "\"\"\"\n",
    "\n",
    "    def generate_solutions(self, meta_prompt: str) -> List[str]:\n",
    "        \"\"\"Generate new candidate solutions\"\"\"\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[{\"role\": \"user\", \"content\": meta_prompt}],\n",
    "                temperature=self.config.temperature,\n",
    "                n=self.config.solutions_per_step\n",
    "            )\n",
    "            return [choice.message.content.strip() for choice in response.choices]\n",
    "        except Exception as e:\n",
    "            print(f\"Generation Error: {e}\")\n",
    "            return []\n",
    "\n",
    "    def optimize(self, data_handler: MMluDataHandler, num_steps: int) -> Dict:\n",
    "        \"\"\"Run optimization process\"\"\"\n",
    "        optimization_results = {\n",
    "            \"steps\": [],\n",
    "            \"best_solution\": None,\n",
    "            \"best_score\": 0\n",
    "        }\n",
    "        \n",
    "        for step in tqdm(range(num_steps)):\n",
    "            # get sample questions for evaluation\n",
    "            eval_questions = data_handler.get_sample_questions(3)\n",
    "            \n",
    "            # meta-prompt to generate solutions\n",
    "            meta_prompt = self.create_meta_prompt(eval_questions)\n",
    "            new_solutions = self.generate_solutions(meta_prompt)\n",
    "            \n",
    "            # Evaluation fo new soltions\n",
    "            for instruction in new_solutions:\n",
    "                if not self.token_manager.is_within_limit(instruction, self.config.max_tokens):\n",
    "                    continue\n",
    "                    \n",
    "                accuracy, token_count = self.scorer.evaluate_solution(instruction, eval_questions)\n",
    "                solution = Solution(instruction, accuracy, token_count)\n",
    "                solution.calculate_score(self.config.token_weight, self.config.max_tokens)\n",
    "                \n",
    "                self.solutions_history.append(solution)\n",
    "                \n",
    "                if solution.combined_score > optimization_results[\"best_score\"]:\n",
    "                    optimization_results[\"best_score\"] = solution.combined_score\n",
    "                    optimization_results[\"best_solution\"] = solution\n",
    "            \n",
    "            # step results\n",
    "            step_results = {\n",
    "                \"step\": step,\n",
    "                \"best_score\": optimization_results[\"best_score\"],\n",
    "                \"avg_score\": np.mean([s.combined_score for s in self.solutions_history[-self.config.solutions_per_step:]])\n",
    "            }\n",
    "            optimization_results[\"steps\"].append(step_results)\n",
    "            \n",
    "        return optimization_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path_to_mmlu_cs_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCombined Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_solution\u001b[38;5;241m.\u001b[39mcombined_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 6\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m config \u001b[38;5;241m=\u001b[39m OptimizationConfig()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Setup data handler\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mMMluDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath_to_mmlu_cs_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m data_handler\u001b[38;5;241m.\u001b[39mprepare_data()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# optimizer\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m, in \u001b[0;36mMMluDataHandler.__init__\u001b[1;34m(self, data_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_path: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m      3\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize with path to MMLU CS data\"\"\"\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_mmlu_cs_data.csv'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Init configuration\n",
    "    config = OptimizationConfig()\n",
    "    \n",
    "    # Setup data handler\n",
    "    data_handler = MMluDataHandler(\"path_to_mmlu_cs_data.csv\")\n",
    "    data_handler.prepare_data()\n",
    "    \n",
    "    # optimizer\n",
    "    optimizer = OptimizerEngine(config)\n",
    "    results = optimizer.optimize(data_handler, config.max_steps)\n",
    "    \n",
    "    # results timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    with open(f\"optimization_results_{timestamp}.json\", \"w\") as f:\n",
    "        json.dump(results, f, indent=2, default=str)\n",
    "\n",
    "        # display results\n",
    "    best_solution = results[\"best_solution\"]\n",
    "    print(f\"\\nBest Solution Found:\")\n",
    "    print(f\"Instruction: {best_solution.instruction}\")\n",
    "    print(f\"Accuracy: {best_solution.accuracy:.2f}\")\n",
    "    print(f\"Token Count: {best_solution.token_count}\")\n",
    "    print(f\"Combined Score: {best_solution.combined_score:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
